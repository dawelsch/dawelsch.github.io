---
layout: "documents"
page_title: "Swarm Cluster"
sidebar_current: "getting-started-networking-installation-swarm"
description: |-
  Setting up a Swarm Cluster.
---

# Installing Contiv Network with Docker Swarm

This page describes how to set up a Contiv cluster using Docker Swarm.

<a name="Prerequisites"/>
## Prerequisites

1. Install Ubuntu 15 or Centos 7.2 on all servers used for the Contiv cluster.
2. Ensure that each server has at least two, and preferably three, interfaces.
3. Choose a server that is on the management network. Run the install procedure below on this node. This *install node* manages the installation in addition to being part of your cluster.
4. In a command shell, use the following commands to set two environment variables:
`export CLUSTER_NODE_IPS=<node_ips> and `export no_proxy=<node_ips>,127.0.0.1,localhost,netmaster`,
where `<node_ip>` is a list of the IP addresses of all nodes in your cluster.
5. If your servers are behind an http proxy, use the following commands to set the proxies on the install node: `export http_proxy=<proxy url>` and  `export https_proxy=<proxy_url>`. 
6. Verify Python is installed on the target machines
7. The setup scripts use the Python module *netaddr* and the Linux utility *bzip2*. If these are not installed on the machine where you are executing these steps, you must install them before proceeding. (You can use the following commands: `yum install bzip2; pip install netaddr`.)
8. (Optional but recommended): Enable passwordless SSH access from the installation server to all the other servers in the cluster. An example is [here](http://www.linuxproblem.org/art_9.html).
9. (Optional but recommended): Enable passwordless sudo on all servers.  An example is
[here](http://askubuntu.com/questions/192050/how-to-run-sudo-command-with-no-password).
10. Make a note of the IP addresses (or DNS names) of all the servers, and of the network
interfaces on which these IP addresses are configured.

<a name="Download"/>
## Step 1: Download the Installer Script
Log into the install server and download the installer script using the following command:

```
wget https://raw.githubusercontent.com/contiv/demo/master/net/net_demo_installer
```

## Step 2: Create the Configuration File
Create the configuration file, `cfg.yml`, and provide connection information for each server.

In the configuration file, `CONNECTION_INFO` is a mandatory section that provides access 
information for all server nodes in the setup.

For every server in the setup, provide the IP/DNS and the control, data interface:

```
    CONNECTION_INFO:
        <server1-ip-or-dns>:
            control: <interface on which control protocols can interact>
            data: <interface used to send data packets>
        <server2-ip-or-dns>:
            control: <interface on which control protocols can interact>
            data: <interface used to send data packets>
```

A sample configuration file can be found here: [sample_cfg.yml](/extras/sample_cfg.yml).

## Step 3: Run the Installer Script

Set execute privileges on and run the installer script as follows:

```
    chmod +x net_demo_installer
    ./net_demo_installer
```

set the environment variable contiv_network_version if a different version of Contiv network is needed.

```
export contiv_network_version="v0.1-06-17-2016.08-42-14.UTC"
```

contiv network version can be obtained from: https://github.com/contiv/netplugin/releases

"aci_gw_image" specifies the docker image used for the aci-gw. This defaults to "contiv/aci-gw:latest".

If your setup requires a different image, just set this "aci_gw_image" environment variable to the "image-name:version".

e.g:

```
export aci_gw_image="contiv/aci-gw:v2"
```

Will fetch container aci-gw of contiv user from docker hub registry with v2 tag.

Run net_demo_installer script.

```
./net_demo_installer
```

*Note*: To restart the services already deployed, run the installer with -r option. This ensures that the services are restarted in a clean state.

```
./net_demo_installer -r
```

- The installer script requests username and password if passwordless ssh is not set during the installation.
- Running the installer with '-c' ("clean") removes any files that are auto-generated by the script.

The installer script performs the following actions:
- Verifies that a supported operating system is installed on the servers.
- Verifies network access to the servers. 
- Creates the Ansible inventory file.
- Sets server provisioning variables that determine the installation mode.
- Runs the Ansible playbook which installs necessary packages and starts the services.

## What to Do Next

Use the Contiv `netctl` commands are used to create and manipulate networks, endpoint groups, and policies.

See the small-scale Vagrant demo [here](swarm.html) to get started.

See the [Tutorials](/documents/tutorials/index.html) section for extended examples of setting up policy-based networks.

See the [Examples](/documents/samples/index.html) section for details on using `netctl` to explore various features of Contiv networking.

## Troubleshooting
Current limitations of the script include the following:

- The installer script must run from one of the server nodes in the cluster. 
- Connections to the servers must be on the default ssh port.
- The default username used is the local hostname.

The script generates many files for bookkeeping during the installation procedure.
These files can be found under `.gen` folder in your installer directory.
To remove these files and start from a clean slate, use the `-c` option as follows:

```
        ./net_demo_installer -c
```

With this option, the script lists the files to remove and prompt you for confirmation to proceed.

If you find any other issues or have suggestions for improvement, please feel free to suggest or contribute.
